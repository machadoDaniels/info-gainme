# Benchmark Configuration
models:
  seeker:
    # model: "Llama-3.1-8B-Instruct"
    # base_url: "http://localhost:8002/v1"

    model: "Qwen3-30B-A3B-Instruct-2507"
    base_url: "http://localhost:8002/v1"

    # model: "Qwen3-30B-A3B-Thinking-2507"
    # base_url: "http://localhost:8001/v1"

    # model: "Qwen3-8B"
    # base_url: "http://localhost:8000/v1"
    timeout: 120.0
    # extra_body:
    #   chat_template_kwargs: 
    #     enable_thinking: false

    # use_reasoning: true
    # temperature: 0.6
    # max_tokens: 10000
  
  oracle:
    model: "Qwen3-8B"
    base_url: "http://localhost:8000/v1"
    timeout: 120.0
    # max_tokens: 150
  
  pruner:
    model: "Qwen3-8B"
    base_url: "http://localhost:8000/v1"
    timeout: 120.0
    # max_tokens: 200

game:
  observability_mode: "PARTIALLY_OBSERVABLE"  # PARTIALLY_OBSERVABLE or FULLY_OBSERVABLE
  max_turns: 30

dataset:
  csv_path: "data/top_40_pop_cities.csv"
  num_targets: null  # null = all targets
  runs_per_target: 3

experiment:
  name: "top40_po_no_cot"
  # name: "top40_fo_no_cot"
  # name: "top40_po"

  tags: {}

output:
  base_dir: "outputs"
  save_conversations: true
  save_graph_plots: true

debug:
  enabled: true